{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import socket\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "class Hosts(Enum):\n",
    "    IMAGEOMICS_SERVER = \"cse-cnc196909s.coeit.osu.edu\"\n",
    "\n",
    "\n",
    "hostname = socket.gethostname()\n",
    "if hostname == Hosts.IMAGEOMICS_SERVER.value:\n",
    "    ROOT_PHENOTYPE_INPUT_DIR = Path(\"/local/scratch/carlyn.1/dna/colors\")\n",
    "    ROOT_PHENOTYPE_OUTPUT_DIR = Path(\"/local/scratch/carlyn.1/dna/colors/processed\")\n",
    "    ROOT_GENOTYPE_INPUT_DIR = Path(\"/local/scratch/carlyn.1/dna/vcfs\")\n",
    "    ROOT_GENOTYPE_OUTPUT_DIR = Path(\"/local/scratch/carlyn.1/dna/processed\")\n",
    "else:\n",
    "    ROOT_PHENOTYPE_INPUT_DIR = Path(\"/local/scratch/david/geno-pheno-data/colors\")\n",
    "    ROOT_PHENOTYPE_OUTPUT_DIR = Path(\n",
    "        \"/local/scratch/david/geno-pheno-data/colors/processed\"\n",
    "    )\n",
    "    ROOT_GENOTYPE_INPUT_DIR = Path(\"/local/scratch/david/geno-pheno-data/dna/\")\n",
    "    ROOT_GENOTYPE_OUTPUT_DIR = Path(\n",
    "        \"/local/scratch/david/geno-pheno-data/dna/processed\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Profiling Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "class ExecutionTimer:\n",
    "    def __init__(self, name=\"\"):\n",
    "        self.name = name\n",
    "        self.end_time = None\n",
    "        self.start_time = time.perf_counter()\n",
    "\n",
    "    def stop(self):\n",
    "        self.end_time = time.perf_counter()\n",
    "\n",
    "    def restart(self):\n",
    "        self.end_time = None\n",
    "        self.start_time = time.perf_counter()\n",
    "\n",
    "    def get_elapsed_time(self):\n",
    "        if self.end_time is None:\n",
    "            print(\"Timer hasn't been stopped yet. Run the stop() method first.\")\n",
    "        return self.end_time - self.start_time\n",
    "\n",
    "    def print_elapsed_time(self):\n",
    "        et = self.get_elapsed_time()\n",
    "        print(f\"{self.name}: {et:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading CSV for Phenotypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect files sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "\n",
    "results = []\n",
    "for root, dirs, paths in os.walk(ROOT_GENOTYPE_OUTPUT_DIR / \"genome/erato\"):\n",
    "    for p in paths:\n",
    "        if p == \"states.csv\":\n",
    "            fsize = os.path.getsize(os.path.join(root, p))\n",
    "            fsize = fsize / math.pow(1024, 3)  # bytes to gigabytes\n",
    "            results.append([fsize, root])\n",
    "\n",
    "for fsize, root in sorted(results, key=lambda x: x[0], reverse=True):\n",
    "    print(f\"({fsize} GB) {root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set initial path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/local/scratch/carlyn.1/dna/processed/genome/erato/Herato1411/states.csv')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_suffix = \"erato_forewings_PCA/PCA_color_3_loadings.csv\"\n",
    "phenotype_loading_path = ROOT_PHENOTYPE_INPUT_DIR / test_suffix\n",
    "phenotype_loading_path\n",
    "\n",
    "test_suffix = \"genome/erato/Herato1411/states.csv\"\n",
    "genotype_loading_path = ROOT_GENOTYPE_OUTPUT_DIR / test_suffix\n",
    "genotype_loading_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Phenotype loading\n",
    "pandas_timer = ExecutionTimer(name=\"pandas-phenotype\")\n",
    "df = pd.read_csv(phenotype_loading_path)\n",
    "pandas_timer.stop()\n",
    "pandas_timer.print_elapsed_time()\n",
    "\n",
    "# Genotype loading\n",
    "pandas_timer = ExecutionTimer(name=\"pandas-genotype\")\n",
    "df = pd.read_csv(genotype_loading_path)\n",
    "pandas_timer.stop()\n",
    "pandas_timer.print_elapsed_time()\n",
    "\n",
    "# Genotype loading\n",
    "pandas_timer = ExecutionTimer(name=\"pandas-arrow-genotype\")\n",
    "df = pd.read_csv(genotype_loading_path, engine=\"pyarrow\")\n",
    "pandas_timer.stop()\n",
    "pandas_timer.print_elapsed_time()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So pandas takes about 20 minutes to read a 1GB file\n",
    "using arrow as the engine seems to break..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Genotype loading\n",
    "pandas_timer = ExecutionTimer(name=\"polars-phenotype\")\n",
    "df = pl.read_csv(phenotype_loading_path)\n",
    "pandas_timer.stop()\n",
    "pandas_timer.print_elapsed_time()\n",
    "\n",
    "# Genotype loading\n",
    "pandas_timer = ExecutionTimer(name=\"polars-genotype\")\n",
    "df = pl.read_csv(genotype_loading_path)\n",
    "pandas_timer.stop()\n",
    "pandas_timer.print_elapsed_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polars takes about 90 seconds!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_timer = ExecutionTimer(name=\"polars-to-pandas-genotype\")\n",
    "pdf = df.to_pandas()\n",
    "pandas_timer.stop()\n",
    "pandas_timer.print_elapsed_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert from polars back to pandas, it takes about 2 minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What about the .parquet format?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_timer = ExecutionTimer(name=\"pandas-to-parquet-genotype\")\n",
    "pdf.to_parquet(\"../../tmp/tmp.parquet\")\n",
    "pandas_timer.stop()\n",
    "pandas_timer.print_elapsed_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Write to parquet, a 1GB file takes ~15.5 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pandas_timer = ExecutionTimer(name=\"pandas-from-parquet-genotype\")\n",
    "pd.read_parquet(\"../../tmp/tmp.parquet\")\n",
    "pandas_timer.stop()\n",
    "pandas_timer.print_elapsed_time()\n",
    "\n",
    "# Genotype loading\n",
    "pandas_timer = ExecutionTimer(name=\"polars-from-parquet-genotype\")\n",
    "df = pl.read_parquet(\"../../tmp/tmp.parquet\")\n",
    "pandas_timer.stop()\n",
    "pandas_timer.print_elapsed_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we transition the data to a parquet file, then the read time from:\n",
    "- pandas => 40 seconds\n",
    "- polars => 2.5 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common Data Operations\n",
    "\n",
    "If we switch to polars and parquet files, then can we do common operations quicker?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Chromosome position metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = df.columns\n",
    "if \"index_level\" in positions[-1]:\n",
    "    positions = positions[:-1]\n",
    "new_positions = [int(pos.replace('\"', \"\")) for pos in positions]\n",
    "new_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original method\n",
    "raw_method_timer = ExecutionTimer(name=\"raw-metadata-loading\")\n",
    "with open(genotype_loading_path, \"r\") as f:\n",
    "    line = f.readline()\n",
    "    columns = line.split(\",\")\n",
    "    # Ignore last column if it has a pandas artifact at the end. Result of incorrect processing :(\n",
    "    if \"index_level\" in columns[-1]:\n",
    "        columns = columns[:-1]\n",
    "    positions = [int(col.replace('\"', \"\")) for col in columns]\n",
    "raw_method_timer.stop()\n",
    "raw_method_timer.print_elapsed_time()\n",
    "\n",
    "# Proposed method\n",
    "pandas_method_timer = ExecutionTimer(name=\"pandas-metadata-loading\")\n",
    "df = pd.read_parquet(\"../../tmp/tmp.parquet\")\n",
    "positions = df.columns\n",
    "if \"index_level\" in positions[-1]:\n",
    "    positions = positions[:-1]\n",
    "new_positions = [int(pos.replace('\"', \"\")) for pos in positions]\n",
    "pandas_method_timer.stop()\n",
    "pandas_method_timer.print_elapsed_time()\n",
    "\n",
    "# Proposed method\n",
    "polars_method_timer = ExecutionTimer(name=\"polars-metadata-loading\")\n",
    "df = pl.read_parquet(\"../../tmp/tmp.parquet\")\n",
    "positions = df.columns\n",
    "if \"index_level\" in positions[-1]:\n",
    "    positions = positions[:-1]\n",
    "new_positions = [int(pos.replace('\"', \"\")) for pos in positions]\n",
    "polars_method_timer.stop()\n",
    "polars_method_timer.print_elapsed_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the raw metadata-loading is quicker (0.0758 seconds), where the polars method with parquet is ~ 2 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading .tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much of the bottleneck in data processing is in the preprocessing step. Once we get data to an ML ready state, it's fast to read into memory. So, let's look at speeding up the preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "\n",
    "genotype_input_path = ROOT_GENOTYPE_INPUT_DIR / \"erato/genome/Herato1411.tsv\"\n",
    "print(genotype_input_path)\n",
    "\n",
    "# Proposed Method\n",
    "polars_method_timer = ExecutionTimer(name=\"polars-tsv-loading\")\n",
    "df = pl.read_csv(genotype_input_path, separator=\"\\t\", has_header=False, quote_char=None)\n",
    "polars_method_timer.stop()\n",
    "polars_method_timer.print_elapsed_time()\n",
    "\n",
    "# Current Method\n",
    "pandas_method_timer = ExecutionTimer(name=\"pandas-tsv-loading\")\n",
    "pdf = pd.read_csv(\n",
    "    genotype_input_path,\n",
    "    sep=\"\\t\",\n",
    "    header=None,\n",
    ")\n",
    "pandas_method_timer.stop()\n",
    "pandas_method_timer.print_elapsed_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polars takes about .9 seconds while pandas takes about 17.1 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "genotype_input_path = ROOT_GENOTYPE_INPUT_DIR / \"erato/genome/Herato1411.tsv\"\n",
    "print(genotype_input_path)\n",
    "df = pd.read_csv(\n",
    "    genotype_input_path,\n",
    "    sep=\"\\t\",\n",
    "    header=None,\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas-tsv-loading: 17.7991\n",
      "org-extract-camids: 0.9018\n",
      "org-extract-states: 38.2941\n",
      "org-intermediates: 11.9993\n",
      "create_ml_ready exe time: 00:01:54\n",
      "org-create-ML: 114.4105\n",
      "org-geno-pipeline: 185.0862\n"
     ]
    }
   ],
   "source": [
    "from gtp.dataloading.tools import butterfly_states_to_ml_ready\n",
    "from gtp.tools.timing import profile_exe_time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "original_genotype_processing_timer = ExecutionTimer(name=\"org-geno-pipeline\")\n",
    "pandas_method_timer = ExecutionTimer(name=\"pandas-tsv-loading\")\n",
    "df = pd.read_csv(\n",
    "    genotype_input_path,\n",
    "    sep=\"\\t\",\n",
    "    header=None,\n",
    ")\n",
    "pandas_method_timer.stop()\n",
    "pandas_method_timer.print_elapsed_time()\n",
    "\n",
    "\n",
    "def extract_states(x):\n",
    "    allele_states = [x.split(\"=\")[1].replace(\"/\", \"|\") for x in x.tolist()]\n",
    "    return pd.Series(allele_states)\n",
    "\n",
    "\n",
    "def extract_camids(x):\n",
    "    #! We are assuming all the camids are the same, we are just extracting from the first row\n",
    "    camid = x.iloc[0].split(\"=\")[0]\n",
    "    return camid\n",
    "\n",
    "\n",
    "def df_extract_states(df):\n",
    "    return df.apply(extract_states)\n",
    "    # return df.map(extract_states_alt)\n",
    "\n",
    "\n",
    "df = df.rename(\n",
    "    {\n",
    "        0: \"Scaffold\",\n",
    "        1: \"Position\",\n",
    "        2: \"Reference Allele\",\n",
    "        3: \"Alternative Allele\",\n",
    "    },\n",
    "    axis=\"columns\",\n",
    ")\n",
    "\n",
    "# Remove duplicate positions\n",
    "df = df.drop_duplicates(subset=[\"Position\"], keep=False)\n",
    "\n",
    "step_timer = ExecutionTimer(name=\"org-extract-camids\")\n",
    "camids = df.iloc[:, 4:].apply(extract_camids)\n",
    "step_timer.stop()\n",
    "step_timer.print_elapsed_time()\n",
    "\n",
    "step_timer = ExecutionTimer(name=\"org-extract-states\")\n",
    "df.iloc[:, 4:] = df_extract_states(df.iloc[:, 4:])\n",
    "step_timer.stop()\n",
    "step_timer.print_elapsed_time()\n",
    "\n",
    "step_timer = ExecutionTimer(name=\"org-intermediates\")\n",
    "states = df.iloc[:, 4:].T.copy(deep=True)\n",
    "states.set_index(camids)\n",
    "positions = df[\"Position\"].values.tolist()\n",
    "column_dict = {i + 4: camids.values[i] for i in range(len(camids))}\n",
    "df = df.rename(columns=column_dict)\n",
    "states.columns = positions\n",
    "step_timer.stop()\n",
    "step_timer.print_elapsed_time()\n",
    "\n",
    "\n",
    "@profile_exe_time(verbose=True)\n",
    "def create_ml_ready(states):\n",
    "    ml_ready = butterfly_states_to_ml_ready(states)\n",
    "    ml_ready = ml_ready.astype(np.bool_)  # Saves significant memory\n",
    "    return ml_ready\n",
    "\n",
    "\n",
    "step_timer = ExecutionTimer(name=\"org-create-ML\")\n",
    "test_ml_ready = create_ml_ready(states)\n",
    "step_timer.stop()\n",
    "step_timer.print_elapsed_time()\n",
    "\n",
    "genotype_data = {\n",
    "    \"all_info\": df,\n",
    "    \"states\": states,\n",
    "    \"positions\": np.array(positions),\n",
    "    \"camids\": np.array(camids.values.tolist()),\n",
    "    \"ml_ready\": test_ml_ready,\n",
    "}\n",
    "\n",
    "original_genotype_processing_timer.stop()\n",
    "original_genotype_processing_timer.print_elapsed_time()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We ran the orignial pipeline on a specific file and found the following speed amounts:\n",
    "- pandas-tsv-loading: 17.7991\n",
    "- org-extract-camids: 0.9018\n",
    "- org-extract-states: 38.2941\n",
    "- org-intermediates: 11.9993\n",
    "- create_ml_ready exe time: 00:01:54\n",
    "- org-create-ML: 114.4105\n",
    "- org-geno-pipeline: 185.0862"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "polars-tsv-loading: 0.7218\n",
      "proposed-extract-camids: 0.0031\n",
      "proposed-extract-states: 0.8367\n",
      "proposed-intermediates: 13.3661\n",
      "proposed-create-ML: 28.8862\n",
      "polars-tsv-loading: 58.5318\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "from gtp.dataloading.tools import butterfly_states_to_ml_ready, get_ml_state_map\n",
    "from gtp.tools.timing import profile_exe_time\n",
    "import numpy as np\n",
    "\n",
    "genotype_input_path = ROOT_GENOTYPE_INPUT_DIR / \"erato/genome/Herato1411.tsv\"\n",
    "\n",
    "# Proposed Method\n",
    "polars_method_timer = ExecutionTimer(name=\"polars-tsv-loading\")\n",
    "df = pl.read_csv(genotype_input_path, separator=\"\\t\", has_header=False, quote_char=None)\n",
    "polars_method_timer.stop()\n",
    "polars_method_timer.print_elapsed_time()\n",
    "\n",
    "\n",
    "original_genotype_processing_timer = ExecutionTimer(name=\"proposed-geno-pipeline\")\n",
    "\n",
    "df = df.rename(\n",
    "    {\n",
    "        \"column_1\": \"Scaffold\",\n",
    "        \"column_2\": \"Position\",\n",
    "        \"column_3\": \"Reference Allele\",\n",
    "        \"column_4\": \"Alternative Allele\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Remove duplicate positions\n",
    "df = df.unique(subset=[\"Position\"], keep=\"none\")\n",
    "\n",
    "step_timer = ExecutionTimer(name=\"proposed-extract-camids\")\n",
    "data_cols = df.columns[4:]\n",
    "camids = [x.split(\"=\")[0] for x in df[0, data_cols].rows()[0]]\n",
    "step_timer.stop()\n",
    "step_timer.print_elapsed_time()\n",
    "\n",
    "step_timer = ExecutionTimer(name=\"proposed-extract-states\")\n",
    "df = df.with_columns(\n",
    "    pl.col(old_col)\n",
    "    .str.split_exact(\"=\", 1)\n",
    "    .struct[1]\n",
    "    .str.replace(\"/\", \"|\")\n",
    "    .alias(old_col)\n",
    "    for old_col in data_cols\n",
    ")\n",
    "step_timer.stop()\n",
    "step_timer.print_elapsed_time()\n",
    "\n",
    "step_timer = ExecutionTimer(name=\"proposed-intermediates\")\n",
    "states = df.select(data_cols).transpose()\n",
    "state_columns = states.columns\n",
    "str_pos = df[:, \"Position\"].cast(pl.String).to_list()\n",
    "states = (\n",
    "    states.with_columns(\n",
    "        pl.Series(camids).alias(\"camids\"),\n",
    "    )\n",
    "    .rename(dict(zip(state_columns, str_pos)))\n",
    "    .select([\"camids\"] + str_pos)\n",
    ")\n",
    "step_timer.stop()\n",
    "step_timer.print_elapsed_time()\n",
    "\n",
    "step_timer = ExecutionTimer(name=\"proposed-create-ML\")\n",
    "values = states.select(\n",
    "    pl.col(str_pos).str.split(\"|\").cast(pl.List(pl.Int32)).list.sum()\n",
    ").rows()\n",
    "np_values = np.array(values)\n",
    "one_hot_size = np_values.max() + 1\n",
    "ml_ready = np.zeros(np_values.shape + (one_hot_size,))\n",
    "ml_ready.reshape(-1, one_hot_size)[np.arange(np_values.size), np_values.reshape(-1)] = 1\n",
    "ml_ready = ml_ready.astype(np.bool_)\n",
    "step_timer.stop()\n",
    "step_timer.print_elapsed_time()\n",
    "\n",
    "genotype_data = {\n",
    "    \"all_info\": df,\n",
    "    \"states\": states,\n",
    "    \"camids\": np.array(camids),\n",
    "    \"positions\": np.array(str_pos),\n",
    "    \"ml_ready\": ml_ready,\n",
    "}\n",
    "\n",
    "polars_method_timer.stop()\n",
    "polars_method_timer.print_elapsed_time()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We ran the proposed pipeline on the same file and found the following speed amounts:\n",
    "- polars-tsv-loading: 0.7218\n",
    "- proposed-extract-camids: 0.0031\n",
    "- proposed-extract-states: 0.8367\n",
    "- proposed-intermediates: 13.3661\n",
    "- proposed-create-ML: 28.8862\n",
    "- polars-tsv-loading: 58.5318"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 216.21% speed up!\n"
     ]
    }
   ],
   "source": [
    "speed_up = (185.0862 / 58.5318) - 1\n",
    "print(f\"A {speed_up * 100:.2f}% speed up!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.True_"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ml_ready == test_ml_ready).all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gtp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
