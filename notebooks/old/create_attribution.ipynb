{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Model\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import torch\n",
    "\n",
    "from models.net import SoyBeanNet\n",
    "\n",
    "\n",
    "\n",
    "MODEL_PATH = \"/home/carlyn.1/dna-trait-analysis/results/feb19/all_genes_forewings_color_3/model.pt\"\n",
    "\n",
    "model = SoyBeanNet(window_size=340202, num_out_dims=10, insize=3, hidden_dim=10).cuda()\n",
    "weights = torch.load(MODEL_PATH)\n",
    "model.load_state_dict(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of input data: 484\n",
      "Length of train data: 480\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "import numpy as np\n",
    "import random\n",
    "from experiments import get_all_gene_experiments\n",
    "from data_tools import load_json, parse_patternize_csv\n",
    "experiments = get_all_gene_experiments(\"erato\", \"forewings\", \"color_3\")\n",
    "\n",
    "pca_data = parse_patternize_csv(experiments[0].pca_loading_path)\n",
    "for i, experiment in enumerate(experiments):\n",
    "    if i == 0:\n",
    "        input_data = np.load(experiment.gene_vcf_path)['arr_0']\n",
    "        metadata = load_json(experiment.metadata_path)\n",
    "    else:\n",
    "        input_data = np.hstack((input_data, np.load(experiment.gene_vcf_path)['arr_0']))\n",
    "        new_metadata = load_json(experiment.metadata_path)\n",
    "        pca_data = parse_patternize_csv(experiment.pca_loading_path)\n",
    "        for j, m in enumerate(metadata):\n",
    "            assert m == new_metadata[j], f\"Metadata does not match: {m} != {new_metadata[j]}\"\n",
    "        \n",
    "\n",
    "train_data = []\n",
    "print(f\"Length of input data: {len(input_data)}\")\n",
    "for name, row in zip(metadata, input_data):\n",
    "    if name+\"_d\" in pca_data:\n",
    "        train_data.append([name, row, pca_data[name+\"_d\"]])\n",
    "print(f\"Length of train data: {len(train_data)}\")\n",
    "\n",
    "random.seed(2)\n",
    "random.shuffle(train_data)\n",
    "train_idx = int(len(train_data) * 0.8)\n",
    "val_idx = int(len(train_data) * 0.1)\n",
    "\n",
    "train_split = train_data[:train_idx]\n",
    "val_split = train_data[train_idx:train_idx+val_idx]\n",
    "test_split = train_data[train_idx+val_idx:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import Occlusion\n",
    "\n",
    "def get_attribution_points(model, dloader):\n",
    "    att_model = Occlusion(model)\n",
    "    attr_total = None\n",
    "    for i, batch in enumerate(dloader):\n",
    "        model.zero_grad()\n",
    "        name, data, pca = batch\n",
    "        attr = att_model.attribute(data.cuda(), target=0, sliding_window_shapes=(1, 200, 3), strides=20, show_progress=True)\n",
    "        #attr = att_m.attribute(data.cuda(), target=0, show_progress=True)\n",
    "        #attr = attr.abs() # Just take the abs value\n",
    "        #attr, _ = attr.max(-1) # Max across 1-hot representation of input\n",
    "        attr = attr.sum(-1)\n",
    "        attr = attr[:, 0] # Only has 1 channel, just extract it\n",
    "        attr = attr.sum(0) # Sum across batch\n",
    "        if attr_total is None:\n",
    "            attr_total = attr.detach().cpu().numpy()\n",
    "        else:\n",
    "            attr_total += attr.detach().cpu().numpy()\n",
    "\n",
    "    #attr_total = attr_total / np.linalg.norm(attr_total, ord=1) # Normalize\n",
    "    return attr_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97b49d20210d4383b33ac60014cbf199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Occlusion attribution:   0%|          | 0/17003 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carlyn.1/miniconda3/envs/dna/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at /opt/conda/conda-bld/pytorch_1699449201450/work/aten/src/ATen/native/Convolution.cpp:1008.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from data_tools import VCF_Dataset\n",
    "\n",
    "dl = DataLoader(VCF_Dataset(test_split), batch_size=256, num_workers=8, shuffle=False)\n",
    "attr_total = get_attribution_points(model, dl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
